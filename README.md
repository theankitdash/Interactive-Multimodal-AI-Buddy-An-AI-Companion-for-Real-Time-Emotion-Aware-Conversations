# Interactive Multimodal AI Buddy

**An AI Companion for Real-Time Emotion-Aware Conversations**

A **desktop application** built with **Electron + React** frontend and **Python FastAPI** backend, providing an intelligent, multimodal AI companion with facial recognition, voice interaction, real-time vision understanding, and personalized long-term memory.

---

## ğŸš€ Overview

The **Interactive Multimodal AI Buddy** is an advanced AI companion designed to engage users in real-time, emotionally intelligent conversations. By integrating multimodal inputsâ€”voice, facial expressions, and live camera visionâ€”the system adapts its responses based on the user's emotional state and visual context, fostering natural and empathetic interactions.

This is a **desktop application** built with modern web technologies (Electron + React) for the UI and Python for AI processing, featuring a **dual-socket architecture** that separates real-time audio streaming from cognitive reasoning.

---

## ğŸ§  Features

- **Meet Deva**: A distinct AI personality that remembers you and evolves with conversation
- **Facial Recognition Authentication**: Secure hands-free login using face embeddings (FaceNet, multi-sample registration)
- **Real-Time Voice Conversation**: Bidirectional audio streaming via Gemini Live API (native audio)
- **Vision Understanding**: Periodic scene analysis using Gemini 2.5 Flash â€” Deva sees and understands your environment
- **Intelligent Reasoning**: Intent classification (Chat / Fact / Event) via NVIDIA Mistral 7B through LangGraph
- **Long-Term Memory**: Stores preferences, memories, and events using PostgreSQL + pgvector with semantic vector search
- **Context Injection**: Retrieves stored knowledge and upcoming events, injecting them into Gemini's live audio context
- **Emotional Intelligence**: Detects emotions from facial expressions and adapts conversational tone
- **Dual-Socket Architecture**: Separates audio streaming (low-latency) from cognitive processing (reasoning + memory)
- **Modern Desktop UI**: Glassmorphism design with animated backgrounds and reactive controls

---

## ğŸ—ï¸ Architecture

The system uses a **dual-WebSocket architecture** bridged by a `SessionRegistry`:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (Electron + React)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ AuthScreen   â”‚  â”‚ AssistantScreenâ”‚  â”‚ AnimatedBackground      â”‚ â”‚
â”‚  â”‚ (FaceNet)    â”‚  â”‚ (Voice + Video)â”‚  â”‚ (Glassmorphism)         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                 â”‚                                       â”‚
â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚         â”‚    â”‚ useAudio   â”‚ useCamera    â”‚ useMicrophone           â”‚
â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚
     REST API        Two WebSockets
          â”‚          â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
          â”‚          â”‚            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Backend (Python FastAPI)                      â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ /api/auth â”‚  â”‚ /ws/assistant     â”‚  â”‚ /ws/cognition           â”‚ â”‚
â”‚  â”‚ (REST)    â”‚  â”‚ (Audio Socket)    â”‚  â”‚ (Cognition Socket)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                         â”‚                          â”‚              â”‚
â”‚                         â”‚    SessionRegistry       â”‚              â”‚
â”‚                         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚
â”‚                         â”‚    (bridges both)        â”‚              â”‚
â”‚                         â”‚                          â”‚              â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚              â”‚ Gemini Live API     â”‚    â”‚ LangGraph Pipeline   â”‚   â”‚
â”‚              â”‚ (Audio Streaming)   â”‚    â”‚ Reasoning â†’ Generationâ”‚  â”‚
â”‚              â”‚ + VisionAnalyzer    â”‚    â”‚ (NVIDIA Mistral 7B)  â”‚   â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                    â”‚              â”‚
â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                         â”‚ PostgreSQL + pgvectorâ”‚   â”‚
â”‚                                         â”‚ (Memory & Events)    â”‚   â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Data Flow:**
1. User speaks â†’ Audio Socket streams to **Gemini Live API** â†’ Audio response streamed back
2. Gemini transcribes user speech â†’ forwarded to **Cognition Socket** via `SessionRegistry`
3. Cognition runs **LangGraph** pipeline: **Reasoning** (Mistral classifies intent, extracts facts/events) â†’ **Generation** (retrieves memories, builds context)
4. Generated context is **injected back** into Gemini's live session for personalized responses
5. **VisionAnalyzer** periodically analyzes camera frames via Gemini 2.5 Flash and injects scene descriptions

---

## ğŸ› ï¸ Technology Stack

### Frontend (Electron + React)
| Layer | Technology |
|-------|-----------|
| Desktop Framework | Electron 40 |
| UI Framework | React 18 + TypeScript |
| Build Tool | Vite 7 |
| Styling | CSS Modules with glassmorphism effects |
| Media | Web Audio API & MediaStream (Camera/Mic) |
| Real-time | Dual WebSocket connections (Audio + Cognition) |

### Backend (Python FastAPI)
| Layer | Technology |
|-------|-----------|
| API Framework | FastAPI (Async, WebSocket) |
| Voice AI | Google Gemini 2.5 Flash (Native Audio Live API) |
| Vision AI | Google Gemini 2.5 Flash (Scene analysis) |
| Reasoning & Generation | NVIDIA Mistral 7B (`mistralai/mistral-7b-instruct-v0.3` via LangChain) |
| Agent Orchestrator | LangGraph (Conditional Reasoning â†’ Generation flow) |
| Embeddings | Sentence Transformers (`all-mpnet-base-v2`, 768 dims) |
| Face Auth | OpenCV + FaceNet-PyTorch (512-dim embeddings) |
| Database | PostgreSQL 13+ with `pgvector` (cosine similarity search) |
| Connection Pooling | `asyncpg` (5â€“20 connections, auto-init schema) |

---

## ğŸ”§ Installation

### Prerequisites
- **Node.js** 22+ and **npm**
- **Python** 3.12+
- **PostgreSQL** 13+ (with `vector` extension)
- Webcam and microphone
- Windows/Linux/macOS

### Setup Steps

1. **Clone the repository**:
   ```bash
   git clone https://github.com/theankitdash/Interactive-Multimodal-AI-Buddy.git
   cd Interactive-Multimodal-AI-Buddy
   ```

2. **Database Setup**:
   - Install PostgreSQL
   - Create database and enable pgvector:
     ```sql
     CREATE DATABASE multimodal_buddy;
     \c multimodal_buddy
     CREATE EXTENSION vector;
     CREATE EXTENSION pgcrypto;
     ```
   > **Note:** The backend auto-initializes all tables, indexes, enums, and triggers on startup via `db_connect.init_db()`.

3. **Backend Setup**:
   ```bash
   # Create virtual environment
   python -m venv .venv
   .venv\Scripts\activate  # Windows
   # source .venv/bin/activate  # Linux/macOS
   
   # Install dependencies
   pip install -r backend/requirements.txt
   ```

4. **Frontend Setup**:
   ```bash
   cd frontend
   npm install
   cd ..
   ```

5. **Configure environment variables**:
   Create a `.env` file in the `backend/` directory:
   ```env
   GEMINI_API_KEY=your_gemini_key
   NVIDIA_API_KEY=your_nvidia_key

   # Database
   DB_USER=postgres
   DB_PASSWORD=your_password
   DB_NAME=multimodal_buddy
   DB_HOST=localhost
   DB_PORT=5432
   ```

6. **Run the application**:

   **Development (Recommended)**:
   ```bash
   cd frontend
   npm run dev
   ```
   *Starts FastAPI backend (port 8000) and Vite dev server (port 5173) concurrently*

   **Production Build**:
   ```bash
   cd frontend
   npm run build:electron
   ```

---

## ğŸ“– Usage

1. **Registration**: 
   - New users register with face data (multi-sample capture for accuracy).
   - Look at the camera to capture 50 face samples for robust embeddings.
   
2. **Login**: 
   - Hands-free login using facial recognition (cosine similarity matching).
   
3. **Chat with Deva**: 
   - Speak naturally! Deva listens and responds with voice in real-time.
   - She sees you through the camera to understand visual context.
   - She remembers your preferences, past conversations, and scheduled events.
   
4. **Controls**:
   - **Mute/Unmute**: Toggle microphone privacy.
   - **Camera**: Toggle video input (vision context updates accordingly).
   - **Logout**: Securely end session.

---

## ğŸ“ Project Structure

```
Interactive-Multimodal-AI-Buddy/
â”œâ”€â”€ backend/                     # Python FastAPI backend
â”‚   â”œâ”€â”€ ai/                     # AI model clients
â”‚   â”‚   â”œâ”€â”€ gemini_handler.py   # Gemini Live API (bidirectional audio streaming)
â”‚   â”‚   â”œâ”€â”€ nvidia_client.py    # Shared NVIDIA Mistral client (reasoning + generation)
â”‚   â”‚   â””â”€â”€ vision_analyzer.py  # Real-time scene analysis (Gemini 2.5 Flash vision)
â”‚   â”œâ”€â”€ graphs/                 # LangGraph workflows
â”‚   â”‚   â””â”€â”€ agent_graph.py      # Conditional Reasoning â†’ Generation pipeline
â”‚   â”œâ”€â”€ nodes/                  # Graph nodes
â”‚   â”‚   â”œâ”€â”€ reasoning.py        # Intent classification + fact/event extraction (Mistral)
â”‚   â”‚   â””â”€â”€ generation.py       # Context-enriched response generation (Mistral)
â”‚   â”œâ”€â”€ routes/                 # API endpoints
â”‚   â”‚   â”œâ”€â”€ auth.py             # Face registration & recognition (REST)
â”‚   â”‚   â”œâ”€â”€ assistant.py        # Audio WebSocket (Gemini Live streaming)
â”‚   â”‚   â”œâ”€â”€ cognition.py        # Cognition WebSocket (reasoning + memory pipeline)
â”‚   â”‚   â””â”€â”€ media.py            # Media utilities
â”‚   â”œâ”€â”€ utils/                  # Shared utilities
â”‚   â”‚   â”œâ”€â”€ db_connect.py       # PostgreSQL pool + auto schema initialization
â”‚   â”‚   â”œâ”€â”€ face_utils.py       # FaceNet embedding extraction
â”‚   â”‚   â””â”€â”€ memory.py           # Vector knowledge store + semantic retrieval
â”‚   â”œâ”€â”€ config.py               # Centralized configuration (API keys, model params)
â”‚   â”œâ”€â”€ models.py               # Pydantic request/response models
â”‚   â”œâ”€â”€ session_registry.py     # Dual-socket session bridge (Audio â†” Cognition)
â”‚   â”œâ”€â”€ main.py                 # App entry point & lifespan manager
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ frontend/                    # Electron + React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # UI Components
â”‚   â”‚   â”‚   â”œâ”€â”€ AssistantScreen.tsx  # Main conversation interface
â”‚   â”‚   â”‚   â”œâ”€â”€ AuthScreen.tsx       # Face registration & login
â”‚   â”‚   â”‚   â””â”€â”€ AnimatedBackground.tsx # Animated glassmorphism backdrop
â”‚   â”‚   â”œâ”€â”€ hooks/              # Custom React hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useAudio.ts     # WebSocket audio streaming & playback
â”‚   â”‚   â”‚   â”œâ”€â”€ useCamera.ts    # Camera stream & frame capture
â”‚   â”‚   â”‚   â””â”€â”€ useMicrophone.ts # Mic capture & PCM encoding
â”‚   â”‚   â”œâ”€â”€ context/            # Global state
â”‚   â”‚   â”‚   â””â”€â”€ AppContext.tsx   # App-wide state (auth, mode, status)
â”‚   â”‚   â”œâ”€â”€ config/             # Frontend configuration
â”‚   â”‚   â”œâ”€â”€ types/              # TypeScript type definitions
â”‚   â”‚   â””â”€â”€ utils/              # Frontend utilities
â”‚   â”œâ”€â”€ electron/               # Electron main process
â”‚   â”œâ”€â”€ public/                 # Static assets
â”‚   â””â”€â”€ package.json            # Dependencies & scripts
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ—„ï¸ Database Schema

The backend auto-creates the following schema on startup:

| Table | Purpose | Key Columns |
|-------|---------|-------------|
| `user_details` | User profiles | `username`, `name`, `face_embedding` (vector 512) |
| `user_knowledge` | Long-term memory (facts) | `fact`, `category` (preference/memory/skill/habit), `embedding` (vector 768) |
| `events` | Scheduled events & reminders | `description`, `event_time`, `type`, `status`, `priority` |

Custom enum types: `knowledge_category`, `event_type`, `event_status`

---

## ğŸš€ Development

### Run in Development Mode
```bash
cd frontend
npm run dev
```
This starts:
- Python FastAPI backend on `http://127.0.0.1:8000`
- Vite dev server on `http://localhost:5173`
- Opens in your browser (use `npm run dev:electron` for Electron window)

### Available Scripts
| Script | Description |
|--------|-------------|
| `npm run dev` | Start backend + frontend concurrently |
| `npm run dev:electron` | Launch Electron desktop window |
| `npm run build:electron` | Build distributable desktop app |
| `npm run typecheck` | TypeScript type checking |
| `npm run lint` | ESLint code linting |
| `npm run format` | Prettier code formatting |

### Build for Production
```bash
cd frontend
npm run build:electron
```
Creates a distributable desktop app in `frontend/release/` directory.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is open source and available under the MIT License.
