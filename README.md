# Interactive Multimodal AI Buddy

**An AI Companion for Real-Time Emotion-Aware Conversations**

---

## üöÄ Overview

The **Interactive Multimodal AI Buddy** is an advanced AI companion designed to engage users in real-time, emotionally intelligent conversations. By integrating multimodal inputs‚Äîsuch as voice, and facial expressions‚Äîthis system adapts its responses based on the user's emotional state, fostering more natural and empathetic interactions.

---

## üß† Features

- **Emotion Recognition**: Utilizes facial expression analysis and voice tone detection to gauge user emotions.
- **Multimodal Interaction**: Supports voice, and video inputs for a comprehensive conversational experience.
- **Contextual Awareness**: Remembers past interactions to provide contextually relevant responses.
- **Real-Time Processing**: Ensures immediate feedback during conversations.
- **Customizable Personality**: Users can adjust the AI's tone and style to match personal preferences.

---

## üõ†Ô∏è Technologies Used

- **Python UI Framework**: Kivy
- **Facial Detection**: OpenCV, Facenet-PyTorch
- **LLM Agent**: Gemini 2.0 Flash
- **LLM Framework**: Langchain (For Personalisation)
- **Database**: PostgreSQL, Chroma (Vector DB)

---

## üîß Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/theankitdash/Interactive-Multimodal-AI-Buddy.git
   cd Interactive-Multimodal-AI-Buddy
