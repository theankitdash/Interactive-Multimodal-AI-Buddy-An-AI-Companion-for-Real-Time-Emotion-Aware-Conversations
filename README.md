# Interactive Multimodal AI Buddy

**An AI Companion for Real-Time Emotion-Aware Conversations**

---

## ğŸš€ Overview

The **Interactive Multimodal AI Buddy** is an advanced AI companion designed to engage users in real-time, emotionally intelligent conversations. By integrating multimodal inputsâ€”such as text, voice, and facial expressionsâ€”this system adapts its responses based on the user's emotional state, fostering more natural and empathetic interactions.

---

## ğŸ§  Features

- **Emotion Recognition**: Utilizes facial expression analysis and voice tone detection to gauge user emotions.
- **Multimodal Interaction**: Supports voice, and video inputs for a comprehensive conversational experience.
- **Contextual Awareness**: Remembers past interactions to provide contextually relevant responses.
- **Real-Time Processing**: Ensures immediate feedback during conversations.
- **Customizable Personality**: Users can adjust the AI's tone and style to match personal preferences.

---

## ğŸ› ï¸ Technologies Used

- **Python UI Framework**: Kivy
- **Facial Detection**: OpenCV, Facenet-PyTorch
- **LLM Agent**: Gemini 2.0 Flash
- **Database**: PostgreSQL

---

## ğŸ”§ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/theankitdash/Interactive-Multimodal-AI-Buddy.git
   cd Interactive-Multimodal-AI-Buddy
